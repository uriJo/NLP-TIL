**지도학습과 비지도학습**

지도학습 : 정답(라벨)이 있는 data를 활용해 학습시키는 방법

1) classification(Knn, naive bayes, support vector, machine decision)

2) regression(linear regression, lasso)

비지도학습 : 정답이 없는 데이터를 비슷한 특징끼리 군집화 하여 나타난 결과를 예측하는 방법

1) clustering 2)K means 3) GAN(generative adversarial network)

- 강화학습

행동 심리학에서 나온 보상을 받으며 학습하는 방법

(아직은 잘 모르겠음) 

**train data, test data**

train data : 모델을 학습할때 사용하는 데이터

test data : 학습한 모델을 평가할때 사용하는 데이터

8:2, 7:3의 비중을 두고 분리한다.

모델 데이터를 학습하기 전, **전처리 하는 과정**이 매우 중요하다.

ex) 스케일이 다른 경우 원치 않는 결과 값을 가져 올 수 있다. → 정규화 

 누락 데이터 → Na/NaN, 0, 평균값, 중간값 으로 채우기 등

 텍스트 → 숫자로 변환

**K 근접 이웃  회귀** 

- 사이킷런에서 사용할 훈련 데이터는 2차원 배열 형태 → reshape() 이용

ex> [1, 2, 3]의 키 데이터가 있을 때 → [[1], [2], [3]] 

(3,) → (3,1) 2차원 배열의 형태로 바꿔줘야 한다.

훈련 데이터에서 좋았는데 테스트 데이터에서 점수가 나쁠 경우 과대 적합 되었다고 말한다. → overfitting

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/094da172-3f19-41b2-b46c-38cbf0f68878/Untitled.png)

반대로 훈련 데이터보다 테스트 데이터의 점수가 높은 경우, 또는 둘다 너무 낮은 경우는 과소 적합되었다고 한다. → underfitting

**overfitting과 underfitting 탐지 방법**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/41c8f364-02b9-4f79-b9e5-07ebd7dba6f5/Untitled.png)

모델의 복잡도와 손실함수에 따른 발생 구간을 분류할 수 있음

1. 과대 적합 발생 구간

모델이 점차 복잡해질수록 gradient descent 기법을 중심으로 모델이 학습되어 train loss는 감소하는 동시에 test loss가 증가하게 된다.

**손실함수**

모델이 예측한 답과 원래 정답의 오차를 표현, 판단하는 함수를 말한다. 

성능을 증명하는 중요한 지표 중 하나다.

**MSE(Mean Squared Error, 평균 제곱 오차)**

모델이 예측한 값과 실제 정답 값의 차를 제곱하여 모두 더한 후 평균을 낸다. 제곱하는 이유는 절대값을 사용하기 위해서다. 

**RMSE(Root Squared Error)**

MSE 방식에 루트를 씌운 것. 값의 왜곡을 보정한다.

**Binary Crossentropy**

이진 분류시 사용하는 손실 함수

Categorical Crossentropy

다중 분류시 사용하는 손실 함수
